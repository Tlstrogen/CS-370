{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T23:57:45.088433Z",
     "start_time": "2024-12-15T23:57:40.500002Z"
    }
   },
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from TreasureMaze import TreasureMaze\n",
    "from GameExperience import GameExperience\n",
    "\n",
    "# Ensure inline plotting for Jupyter Notebook\n",
    "%matplotlib inline\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "c9523ad741f32476",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "id": "638e441d144d71d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T21:22:45.695067Z",
     "start_time": "2024-12-15T21:22:45.689369Z"
    }
   },
   "source": [
    "maze = np.array([\n",
    "    [ 1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
    "    [ 1.,  0.,  1.,  1.,  1.,  0.,  1.,  1.],\n",
    "    [ 1.,  1.,  1.,  1.,  0.,  1.,  0.,  1.],\n",
    "    [ 1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.],\n",
    "    [ 1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.],\n",
    "    [ 1.,  1.,  1.,  0.,  1.,  0.,  0.,  0.],\n",
    "    [ 1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.],\n",
    "    [ 1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.]\n",
    "])"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "2c34571d11cf2332",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T21:22:45.725270Z",
     "start_time": "2024-12-15T21:22:45.701538Z"
    }
   },
   "source": [
    "def show(qmaze):\n",
    "    plt.grid('on')\n",
    "    nrows, ncols = qmaze.maze.shape\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticks(np.arange(0.5, nrows, 1))\n",
    "    ax.set_yticks(np.arange(0.5, ncols, 1))\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    canvas = np.copy(qmaze.maze)\n",
    "    for row,col in qmaze.visited:\n",
    "        canvas[row,col] = 0.6\n",
    "    pirate_row, pirate_col, _ = qmaze.state\n",
    "    canvas[pirate_row, pirate_col] = 0.3   # pirate cell\n",
    "    canvas[nrows-1, ncols-1] = 0.9 # treasure cell\n",
    "    img = plt.imshow(canvas, interpolation='none', cmap='gray')\n",
    "    return img"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "4b3f64f43c026356",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T21:22:46.112862Z",
     "start_time": "2024-12-15T21:22:46.106866Z"
    }
   },
   "source": [
    "# Define constants for actions\n",
    "LEFT = 0\n",
    "UP = 1\n",
    "RIGHT = 2\n",
    "DOWN = 3\n",
    "\n",
    "\n",
    "\n",
    "# Actions dictionary\n",
    "actions_dict = {\n",
    "    LEFT: 'left',\n",
    "    UP: 'up',\n",
    "    RIGHT: 'right',\n",
    "    DOWN: 'down',\n",
    "}\n",
    "num_actions = len(actions_dict)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "fbe6c10a54ad271c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T21:22:46.134688Z",
     "start_time": "2024-12-15T21:22:46.129191Z"
    }
   },
   "source": [
    "# Function to play the game\n",
    "def play_game(model, qmaze, pirate_cell):\n",
    "    qmaze.reset(pirate_cell)\n",
    "    envstate = qmaze.observe()\n",
    "    while True:\n",
    "        prev_envstate = envstate\n",
    "        # get next action\n",
    "        q = model.predict(prev_envstate)\n",
    "        action = np.argmax(q[0])\n",
    "\n",
    "        # apply action, get rewards and new state\n",
    "        envstate, reward, game_status = qmaze.act(action)\n",
    "        if game_status == 'win':\n",
    "            return True\n",
    "        elif game_status == 'lose':\n",
    "            return False\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "f07fb2f57b27ea4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T21:22:46.214499Z",
     "start_time": "2024-12-15T21:22:46.208362Z"
    }
   },
   "source": [
    "def completion_check(model, qmaze):\n",
    "    for cell in qmaze.free_cells:\n",
    "        if not qmaze.valid_actions(cell):\n",
    "            return False\n",
    "        if not play_game(model, qmaze, cell):\n",
    "            return False\n",
    "    return True"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "412f5be53cc8d2a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T21:22:46.328458Z",
     "start_time": "2024-12-15T21:22:46.322133Z"
    }
   },
   "source": [
    "def build_model(maze):\n",
    "    # Calculate the size of the input layer (number of features)\n",
    "    input_size = np.prod(maze.shape)\n",
    "\n",
    "    # Define the model\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # Add an input layer\n",
    "    model.add(tf.keras.layers.Input(shape=(input_size,)))\n",
    "\n",
    "    # Add hidden layers\n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "\n",
    "    # Add output layer\n",
    "    model.add(tf.keras.layers.Dense(4, activation='linear'))  # 4 outputs for LEFT, UP, RIGHT, DOWN\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "    return model\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "fc995bffe2cd5e0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T21:22:46.365354Z",
     "start_time": "2024-12-15T21:22:46.351549Z"
    }
   },
   "source": [
    "def qtrain(model, maze, **opt):\n",
    "\n",
    "    # Configurable parameters\n",
    "    n_epoch = opt.get('n_epoch', 15000)\n",
    "    max_memory = opt.get('max_memory', 1000)\n",
    "    data_size = opt.get('data_size', 50)\n",
    "    epsilon = opt.get('epsilon', 1.0)\n",
    "    min_epsilon = opt.get('min_epsilon', 0.05)\n",
    "    epsilon_decay = opt.get('epsilon_decay', 0.995)\n",
    "\n",
    "    start_time = datetime.datetime.now()\n",
    "\n",
    "    # Initialize environment\n",
    "    qmaze = TreasureMaze(maze)\n",
    "    experience = GameExperience(model, max_memory=max_memory)\n",
    "\n",
    "    win_history = []\n",
    "    hsize = qmaze.maze.size // 2  # Window size for win rate calculation\n",
    "\n",
    "    print(\"Starting Training...\")\n",
    "\n",
    "    # Metrics for logging\n",
    "    for epoch in range(n_epoch):\n",
    "        # Start a new episode\n",
    "        agent_start = qmaze.free_cells[np.random.choice(len(qmaze.free_cells))]\n",
    "        qmaze.reset(agent_start)\n",
    "        envstate = qmaze.observe()\n",
    "\n",
    "        n_episodes = 0\n",
    "        loss = 0.0\n",
    "        early_stop = False  # Track early stop\n",
    "\n",
    "        while True:\n",
    "            prev_envstate = envstate\n",
    "\n",
    "            # Choose action\n",
    "            if np.random.rand() < epsilon:\n",
    "                action = np.random.choice(qmaze.valid_actions())\n",
    "            else:\n",
    "                q_values = experience.predict(envstate)\n",
    "                action = np.argmax(q_values)\n",
    "\n",
    "            # Perform action\n",
    "            envstate, reward, game_status = qmaze.act(action)\n",
    "\n",
    "            # Stop early if misstep reward is encountered\n",
    "            if reward in (-0.25, -0.75):\n",
    "                print(f\"Stopped epoch {epoch} early due to reward {reward:.2f} at step {n_episodes}.\")\n",
    "                early_stop = True\n",
    "                break\n",
    "\n",
    "            # Remember experience for replay\n",
    "            experience.remember([prev_envstate, action, reward, envstate, game_status == 'lose'])\n",
    "\n",
    "            # Train model\n",
    "            inputs, targets = experience.get_data(data_size)\n",
    "            h = model.fit(inputs, targets, epochs=1, verbose=0)\n",
    "            loss = h.history['loss'][0]\n",
    "\n",
    "            n_episodes += 1\n",
    "            if game_status in ('win', 'lose'):\n",
    "                win_history.append(1 if game_status == 'win' else 0)\n",
    "                break\n",
    "\n",
    "        # Update win rate safely\n",
    "        if len(win_history) > 0:\n",
    "            win_rate = np.mean(win_history[-hsize:]) if len(win_history) >= hsize else np.mean(win_history)\n",
    "        else:\n",
    "            win_rate = 0.0\n",
    "\n",
    "        # Print epoch stats even if stopped early\n",
    "        dt = datetime.datetime.now() - start_time\n",
    "        t = format_time(dt.total_seconds())\n",
    "        print(f\"Epoch: {epoch:04d}/{n_epoch-1} | Loss: {loss:.5f} | Episodes: {n_episodes} | \"\n",
    "              f\"Win count: {sum(win_history)} | Win rate: {win_rate:.3f} | Time: {t}\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        # Early stopping based on win rate\n",
    "        if win_rate > 0.9:\n",
    "            epsilon = min_epsilon\n",
    "        if len(win_history) >= hsize and sum(win_history[-hsize:]) == hsize:\n",
    "            print(f\"Reached 100% win rate at epoch: {epoch}\")\n",
    "            break\n",
    "\n",
    "        # Decay epsilon\n",
    "        if epsilon > min_epsilon:\n",
    "            epsilon *= epsilon_decay\n",
    "\n",
    "    # Total training time\n",
    "    dt = datetime.datetime.now() - start_time\n",
    "    t = format_time(dt.total_seconds())\n",
    "    print(f\"Training Complete! Total epochs: {epoch}, Memory: {max_memory}, Data size: {data_size}, Time: {t}\")\n",
    "\n",
    "    return {\"win_rate\": win_rate, \"loss\": loss}\n",
    "\n",
    "\n",
    "def format_time(seconds):\n",
    "    \"\"\"Formats time in seconds into hours, minutes, or seconds.\"\"\"\n",
    "    if seconds < 400:\n",
    "        return \"%.1f seconds\" % seconds\n",
    "    elif seconds < 4000:\n",
    "        return \"%.2f minutes\" % (seconds / 60.0)\n",
    "    else:\n",
    "        return \"%.2f hours\" % (seconds / 3600.0)\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "a88a52900c575f31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-15T21:22:46.537799Z",
     "start_time": "2024-12-15T21:22:46.383719Z"
    }
   },
   "source": [
    "qmaze = TreasureMaze(maze)\n",
    "show(qmaze)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b0078a0e50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "b225a09a9a6564f6",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-12-15T21:22:46.597946Z"
    }
   },
   "source": [
    "model = build_model(maze)\n",
    "qtrain(model, maze, n_epoch=1000, max_memory=500, data_size=20)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training...\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 117ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 54ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 64ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 62ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 67ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 68ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 63ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 78ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 76ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 69ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 57ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 61ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 63ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 71ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 54ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 65ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 55ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 66ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 85ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 65ms/step\n",
      "Stopped epoch 0 early due to reward -0.25 at step 4.\n",
      "Epoch: 0000/999 | Loss: 0.00898 | Episodes: 4 | Win count: 0 | Win rate: 0.000 | Time: 4.7 seconds\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 78ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 60ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 61ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 67ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 65ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 74ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 72ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 62ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 83ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 70ms/step\n",
      "Stopped epoch 1 early due to reward -0.25 at step 1.\n",
      "Epoch: 0001/999 | Loss: 0.00739 | Episodes: 1 | Win count: 0 | Win rate: 0.000 | Time: 6.2 seconds\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 77ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 75ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 69ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 75ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 74ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 80ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 55ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 77ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 65ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 83ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 61ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 69ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 61ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 79ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 69ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 69ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 61ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 75ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 69ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 61ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 59ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 83ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 68ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 56ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 67ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 69ms/step\n",
      "Epoch: 0002/999 | Loss: 0.04336 | Episodes: 2 | Win count: 1 | Win rate: 1.000 | Time: 9.8 seconds\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 75ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 69ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 67ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 67ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 69ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 69ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 68ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 72ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 63ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 61ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 74ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 73ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 64ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 65ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 62ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 69ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 64ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 57ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 59ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 67ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 56ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 68ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1945d2db7cc3c92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_check(model, qmaze)\n",
    "show(qmaze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61a47874d21844b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pirate_start = (0, 0)\n",
    "play_game(model, qmaze, pirate_start)\n",
    "show(qmaze)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
